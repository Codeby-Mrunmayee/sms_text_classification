{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjz7cAuqHnXq",
        "outputId": "e8649be7-3df5-4e5c-df8e-22a1b77cab2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf-nightly in /usr/local/lib/python3.11/dist-packages (2.20.0.dev20250516)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (24.2)\n",
            "Requirement already satisfied: protobuf>=4.21.6 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (1.71.0)\n",
            "Requirement already satisfied: tb-nightly~=2.19.0.a in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (2.19.0a20250218)\n",
            "Requirement already satisfied: keras-nightly>=3.6.0.dev in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (3.10.0.dev2025051603)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tf-nightly) (0.5.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tf-nightly) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras-nightly>=3.6.0.dev->tf-nightly) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras-nightly>=3.6.0.dev->tf-nightly) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras-nightly>=3.6.0.dev->tf-nightly) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tf-nightly) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tf-nightly) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tf-nightly) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tf-nightly) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tb-nightly~=2.19.0.a->tf-nightly) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tb-nightly~=2.19.0.a->tf-nightly) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tb-nightly~=2.19.0.a->tf-nightly) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tb-nightly~=2.19.0.a->tf-nightly) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nightly>=3.6.0.dev->tf-nightly) (0.1.2)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (4.9.8)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.4.0)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.7.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.1.9)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (1.12.2)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (4.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (2.0.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (5.29.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (18.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (2.32.3)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.17.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (3.1.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (4.67.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.17.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (6.5.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (4.13.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2025.4.26)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-datasets) (25.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from promise->tensorflow-datasets) (1.17.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing->tensorflow-datasets) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.70.0)\n",
            "2.20.0-dev20250516\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  !pip install tf-nightly\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "!pip install tensorflow-datasets\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq7gcB9sHwDb",
        "outputId": "6ca5d9ba-5e29-4612-ad32-05763b4ae881"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-16 18:17:24--  https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 172.67.70.149, 104.26.3.33, 104.26.2.33, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|172.67.70.149|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 358233 (350K) [text/tab-separated-values]\n",
            "Saving to: ‘train-data.tsv.1’\n",
            "\n",
            "\rtrain-data.tsv.1      0%[                    ]       0  --.-KB/s               \rtrain-data.tsv.1    100%[===================>] 349.84K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2025-05-16 18:17:24 (56.5 MB/s) - ‘train-data.tsv.1’ saved [358233/358233]\n",
            "\n",
            "--2025-05-16 18:17:24--  https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 172.67.70.149, 104.26.3.33, 104.26.2.33, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|172.67.70.149|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 118774 (116K) [text/tab-separated-values]\n",
            "Saving to: ‘valid-data.tsv.1’\n",
            "\n",
            "valid-data.tsv.1    100%[===================>] 115.99K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-05-16 18:17:24 (34.5 MB/s) - ‘valid-data.tsv.1’ saved [118774/118774]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Preprocess text to remove punctuation and lowercase\n",
        "def preprocess_text(texts):\n",
        "    return [re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text.lower()) for text in texts]\n",
        "\n",
        "# Load the data into pandas DataFrames\n",
        "train_data = pd.read_csv(train_file_path, sep='\\t', header=None, names=['label', 'message'])\n",
        "test_data = pd.read_csv(test_file_path, sep='\\t', header=None, names=['label', 'message'])\n",
        "\n",
        "# Encode labels: 'ham' → 0, 'spam' → 1\n",
        "train_data['label'] = train_data['label'].map({'ham': 0, 'spam': 1})\n",
        "test_data['label'] = test_data['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Preprocess messages\n",
        "train_messages = preprocess_text(train_data['message'].values)\n",
        "test_messages = preprocess_text(test_data['message'].values)\n",
        "\n",
        "# Text vectorization\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "max_vocab_size = 1000\n",
        "max_sequence_length = 100\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=max_vocab_size, output_mode='int', output_sequence_length=max_sequence_length)\n",
        "vectorizer.adapt(train_messages)\n",
        "\n",
        "# Vectorize messages\n",
        "X_train = vectorizer(train_messages)\n",
        "X_test = vectorizer(test_messages)\n",
        "\n",
        "y_train = train_data['label'].values\n",
        "y_test = test_data['label'].values"
      ],
      "metadata": {
        "id": "WL-Gt812H1dx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(input_dim=max_vocab_size, output_dim=64, input_length=max_sequence_length),\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(32, return_sequences=True)),\n",
        "    keras.layers.GlobalMaxPooling1D(),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
        "\n",
        "# Define prediction function\n",
        "def predict_message(pred_text):\n",
        "    cleaned_text = preprocess_text([pred_text])  # clean before predicting\n",
        "    vectorized_text = vectorizer(cleaned_text)\n",
        "    prediction = model.predict(vectorized_text)[0][0]\n",
        "    label = \"spam\" if prediction > 0.5 else \"ham\"\n",
        "    return [float(prediction), label]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S_TUMIYH22h",
        "outputId": "4b873eb8-427b-4be4-f3dd-c2c90614911f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8729 - loss: 0.4172 - val_accuracy: 0.9684 - val_loss: 0.0988\n",
            "Epoch 2/5\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9775 - loss: 0.0772 - val_accuracy: 0.9799 - val_loss: 0.0620\n",
            "Epoch 3/5\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9868 - loss: 0.0443 - val_accuracy: 0.9828 - val_loss: 0.0568\n",
            "Epoch 4/5\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9919 - loss: 0.0306 - val_accuracy: 0.9813 - val_loss: 0.0641\n",
            "Epoch 5/5\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9926 - loss: 0.0245 - val_accuracy: 0.9828 - val_loss: 0.0610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "\n",
        "# Test a single message\n",
        "\n",
        "pred_text = \"how are you doing today?\"\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmqEG5N8H6Uz",
        "outputId": "2e1c7cc3-3cbe-4bf5-e7a3-942dc4a20bdf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
            "[0.0008196687558665872, 'ham']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won £1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fjlzuq3IBFJ",
        "outputId": "7f3409e1-c568-4e51-ef57-1588dd6c8dd0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "You passed the challenge. Great job!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dxye4wY_ICTM",
        "outputId": "674e80e8-f535-4d6a-c264-7c9db55cf543"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9820 - loss: 0.0642\n",
            "Test Accuracy: 0.982758641242981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Predict probabilities on TRAINING DATA\n",
        "train_predictions = model.predict(X_train)\n",
        "\n",
        "# Convert probabilities to labels based on threshold 0.5\n",
        "train_pred_labels = [\"spam\" if p > 0.5 else \"ham\" for p in train_predictions.flatten()]\n",
        "\n",
        "# To compare with actual labels\n",
        "actual_labels = [\"spam\" if l == 1 else \"ham\" for l in y_train]\n",
        "\n",
        "# Let's print some predictions and their actual labels\n",
        "for i in range(10):\n",
        "    print(f\"Message: {train_data['message'].iloc[i]}\")\n",
        "    print(f\"Actual: {actual_labels[i]}, Predicted: {train_pred_labels[i]}\")\n",
        "    print(f\"Prediction Score: {train_predictions[i][0]:.4f}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OSdWR5FJG8j",
        "outputId": "03e084df-5f6b-4433-a3e7-f90431743f48"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "Message: ahhhh...just woken up!had a bad dream about u tho,so i dont like u right now :) i didnt know anything about comedy night but i guess im up for it.\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0009\n",
            "\n",
            "Message: you can never do nothing\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0009\n",
            "\n",
            "Message: now u sound like manky scouse boy steve,like! i is travelling on da bus home.wot has u inmind 4 recreation dis eve?\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0024\n",
            "\n",
            "Message: mum say we wan to go then go... then she can shun bian watch da glass exhibition...\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0001\n",
            "\n",
            "Message: never y lei... i v lazy... got wat? dat day ü send me da url cant work one...\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0001\n",
            "\n",
            "Message: in xam hall boy asked girl tell me the starting term for dis answer i can den manage on my own after lot of hesitation n lookin around silently she said the! intha ponnungale ipaditan;)\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0007\n",
            "\n",
            "Message: genius what's up. how your brother. pls send his number to my skype.\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0002\n",
            "\n",
            "Message: they finally came to fix the ceiling.\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0055\n",
            "\n",
            "Message: urgent! call 09066350750 from your landline. your complimentary 4* ibiza holiday or 10,000 cash await collection sae t&cs po box 434 sk3 8wp 150 ppm 18+\n",
            "Actual: spam, Predicted: spam\n",
            "Prediction Score: 0.9991\n",
            "\n",
            "Message: now that you have started dont stop. just pray for more good ideas and anything i see that can help you guys i.ll forward you a link.\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0230\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the TESTING DATA\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Convert predicted probabilities to labels\n",
        "test_pred_labels = [\"spam\" if p > 0.5 else \"ham\" for p in test_predictions.flatten()]\n",
        "\n",
        "# Convert actual labels to 'ham' or 'spam'\n",
        "actual_test_labels = [\"spam\" if l == 1 else \"ham\" for l in y_test]\n",
        "\n",
        "# Print the first 10 predictions with actual values\n",
        "for i in range(10):\n",
        "    print(f\"Message: {test_data['message'].iloc[i]}\")\n",
        "    print(f\"Actual: {actual_test_labels[i]}, Predicted: {test_pred_labels[i]}\")\n",
        "    print(f\"Prediction Score: {test_predictions[i][0]:.4f}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqD9dZA4JXUZ",
        "outputId": "d6a4c952-c53f-4db1-fab0-c91a4f7728a3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Message: i am in hospital da. . i will return home in evening\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0001\n",
            "\n",
            "Message: not much, just some textin'. how bout you?\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0010\n",
            "\n",
            "Message: i probably won't eat at all today. i think i'm gonna pop. how was your weekend? did u miss me?\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0001\n",
            "\n",
            "Message: don‘t give a flying monkeys wot they think and i certainly don‘t mind. any friend of mine and all that!\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0046\n",
            "\n",
            "Message: who are you seeing?\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0151\n",
            "\n",
            "Message: your opinion about me? 1. over 2. jada 3. kusruthi 4. lovable 5. silent 6. spl character 7. not matured 8. stylish 9. simple pls reply..\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0037\n",
            "\n",
            "Message: yesterday its with me only . now am going home.\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0003\n",
            "\n",
            "Message: yes. it's all innocent fun. o:-)\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0003\n",
            "\n",
            "Message: a boy was late 2 home. his father: power of frndship\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0003\n",
            "\n",
            "Message: is ur changes 2 da report big? cos i've already made changes 2 da previous report.\n",
            "Actual: ham, Predicted: ham\n",
            "Prediction Score: 0.0003\n",
            "\n"
          ]
        }
      ]
    }
  ]
}